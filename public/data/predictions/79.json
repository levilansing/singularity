{"tldr_summary":"While AI labs promise AGI by 2027, Douglas Hofstadter—whose 1979 \"Gödel, Escher, Bach\" remains the definitive work on consciousness and self-reference—asks an inconvenient question: are we building intelligence or just really good autocomplete? His theory of \"strange loops\" suggests consciousness emerges from recursive self-referential patterns where awareness observes itself observing itself, creating genuine subjective experience. Current LLMs, no matter how large, lack this fundamental architecture. They're sophisticated pattern matchers without genuine interiority. Hofstadter's implicit timeline stretches to 2070 or beyond because he's not convinced we've even started building the right kind of system. It's like trying to create consciousness by making calculators bigger—you might get impressive calculations, but you won't get experience. His work suggests that until we solve the hard problem of how recursive self-reference creates subjective awareness, we're not building conscious AI, we're building increasingly convincing simulations of it. The coffee mug on his desk has more genuine self-awareness than Claude.","criteria_definition":"Genuine consciousness requiring strange loops and recursive self-awareness, not computational sophistication alone","confidence_level":"Low confidence that consciousness emerges from current architectures without solving the hard problem of recursive self-reference","source_name":"Hofstadter interviews","source_url":"https://en.wikipedia.org/wiki/Douglas_Hofstadter","concept_keys":["superintelligence"]}