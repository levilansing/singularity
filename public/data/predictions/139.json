{"tldr_summary":"Nick Bostrom, the Oxford philosopher who literally wrote the book on superintelligence, presents a fascinating paradox: expert surveys suggest 50% probability by 2040 and 90% by 2075, yet he notes there's 'no obvious clear barrier' preventing superintelligence from arriving much sooner—even next year. This captures the fundamental uncertainty around AI timelines: we can see no insurmountable obstacles, but we also can't predict which breakthroughs will unlock recursive self-improvement. Bostrom's framework distinguishes between human-level AI and superintelligence—the latter having unlimited potential for intelligence growth at rates that would make human genius look like insect cognition. His thought experiment is chilling: humans are weaker than bears and chimpanzees, but we're smarter, so they live in our zoos. What happens when AI is to humans what humans are to chimps? The 2040-2075 range reflects expert caution, but Bostrom's 'no obvious barrier' comment suggests the timeline could compress dramatically with the right algorithmic insights. His work remains foundational in AI safety circles, establishing the intellectual framework for why superintelligence poses existential risk even without malicious intent.","criteria_definition":"Superintelligence with unlimited potential for intelligence growth exceeding human capabilities","confidence_level":"Survey-based: 50% by 2040, 90% by 2075; notes 'no obvious clear barrier' to near-term development","source_name":"Bostrom survey of 95 researchers","source_url":"https://www.freethink.com/series/uprising/future-of-ai-superintelligence","concept_keys":["agi","recursive-self-improvement","alignment"]}