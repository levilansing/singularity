{"tldr_summary":"Christof Koch, the neuroscientist who literally bet philosopher David Chalmers a case of wine that we'd understand consciousness by 2023 (spoiler: he lost), has a spicy take on AI consciousness. Based on Integrated Information Theory, Koch argues that conventional computers running in the cloud will 'never be conscious'—they can do everything humans do, just without the lights being on inside. His position: consciousness isn't a clever algorithm or emergent property of complexity, it's a specific structure of causal relationships. A perfect software simulation of your brain? Still philosophical zombie territory. Von Neumann architectures are fundamentally the wrong substrate, like trying to get wet by looking at a picture of water. Koch admits advanced computers will achieve 'superhuman capabilities' and could theoretically gain consciousness if built with different architectures (analog? quantum? he's vague), but today's AI? All performance, no experience. It's the ultimate 'I can't believe it's not consciousness' argument, and it puts him at odds with basically everyone in AI who thinks sufficient complexity equals sentience.","criteria_definition":"True consciousness requires causal structure, not computation—von Neumann architectures are categorically incapable regardless of sophistication","confidence_level":"Extremely high confidence based on Integrated Information Theory—computers fundamentally cannot be conscious regardless of capability","source_name":"Neuroscience research","source_url":"https://www.scientificamerican.com/article/a-25-year-old-bet-about-consciousness-has-finally-been-settled/","concept_keys":["superintelligence"]}