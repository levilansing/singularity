{"tldr_summary":"Metaculus draws a sharp line between 'weak' and 'strong' AGI, and their 1,800 forecasters put the real deal—full human-level performance across adversarial Turing tests, every academic benchmark, coding challenges, and physical robotics—at June 2033. That's six years after their weak AGI estimate, capturing the community's view that crossing from 'pretty good' to 'actually matches humans at everything' involves serious engineering challenges. The resolution criteria are brutal: 75%+ on every MMLU task, 90% mean across all of them, 90% on APPS coding, plus the ability to assemble a Ferrari model kit. This isn't narrow AI excellence; it's genuine human-replacement capability. The timeline has compressed spectacularly—from 50 years away in 2022 to just 7 years in 2026—but the 12-year spread between lower and upper quartiles (December 2026 to March 2039) reveals massive disagreement. Some forecasters think we're basically there; others see fundamental obstacles requiring another decade-plus. The platform's track record on near-term tech predictions lends credibility, but betting on 2033 means believing current scaling laws hold and alignment doesn't become an insurmountable bottleneck.","criteria_definition":"AI passing adversarial Turing tests, achieving 90%+ on all MMLU tasks, 90% on APPS coding, plus general robotic capabilities","confidence_level":"1,800 forecasters with 12+ year uncertainty range (2026-2039 quartiles); dramatically shifted from 2072 to 2033 in 4 years","source_name":"Metaculus (~1800 forecasters)","source_url":"https://www.metaculus.com/questions/5121/when-will-the-first-general-ai-system-be-devised-tested-and-publicly-announced/","concept_keys":["agi","scaling-hypothesis","turing-test","alignment","prediction-markets"]}