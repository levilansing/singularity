{"tldr_summary":"The Future of Life Institute—the organization that got over 30,000 people to sign a letter calling for an AI pause—is putting AGI arrival somewhere between 2030 and 2050, with 'likely within 30 years' as their best guess. But FLI isn't really in the prediction business; they're in the 'please take existential risk seriously' business. Their timeline is less about pinpointing when AGI arrives and more about establishing urgency for safety work. The 30-year window is wide enough to avoid looking foolish if progress stalls, but near enough to justify their mission of steering transformative technology away from catastrophe. FLI's whole model assumes AGI is coming soon enough that we need to act now on alignment, governance, and safety frameworks. Whether that's prescient or alarmist depends entirely on whether their timeline proves accurate.","criteria_definition":"AGI arrival within 30 years with focus on existential risk mitigation rather than specific capabilities","confidence_level":"High likelihood assessment based on recent AI progress trajectories","source_name":"FLI AI risk research","source_url":"https://futureoflife.org/","concept_keys":["agi","alignment"]}