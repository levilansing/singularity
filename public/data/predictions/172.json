{"tldr_summary":"Susan Schneider, founding director of the Center for the Future of AI, Mind, & Society at Florida Atlantic University, throws cold water on the idea that we're anywhere close to conscious AI. The philosopher and former NASA/Library of Congress Chair in Astrobiology argues that building truly conscious artificial intelligence faces fundamental philosophical barriers that silicon valley types conveniently ignore. The 'hard problem of consciousness'—explaining why subjective experience exists at all—remains completely unsolved, and Schneider suggests it may be unsolvable within our current frameworks. While tech executives race to build AGI and superintelligence, she points out they're essentially trying to create something (consciousness) that we don't even understand in biological systems. Her work bridges philosophy of mind and AI safety, asking uncomfortable questions like 'what is it like to be an AI?' that have no clear answers. If consciousness is actually required for true general intelligence, we might be building very sophisticated calculators while claiming they're minds.","criteria_definition":"Machine consciousness and superintelligence requiring solution to the hard problem of consciousness and subjective experience","confidence_level":"High confidence that consciousness presents fundamental barriers that may never be solved, based on philosophical analysis rather than technical timelines","source_name":"Philosophy of AI consciousness","source_url":"https://en.wikipedia.org/wiki/Susan_Schneider","concept_keys":["superintelligence","alignment"]}