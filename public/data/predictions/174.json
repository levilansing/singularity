{"tldr_summary":"Timnit Gebru — the computer scientist famously fired from Google in 2020 for co-authoring the 'Stochastic Parrots' paper on LLM risks — doesn't think AGI is coming in 2027, 2035, or ever, because she thinks the whole concept is bunk. Speaking at Stanford in February 2023, she asked the audience: 'Why attempt to build some undefined system that kind of sounds like a god?' She drew parallels between the AGI movement and first-wave eugenics, arguing both promise utopia while entrenching power hierarchies. While Silicon Valley debates extinction risk timelines, Gebru points to Kenyan content moderators paid $1.50/hour, artists whose work is scraped for training data, and biased facial recognition causing false arrests. She co-coined 'TESCREAL' to describe the overlapping ideologies — transhumanism, singularitarianism, effective altruism — she sees driving AGI hype. Her counter-vision: small, well-scoped, community-rooted AI systems. Whether you agree or not, she's the field's most prominent voice saying the emperor has no clothes.","criteria_definition":"AGI is an undefined, unscoped system rooted in eugenics ideology; trying to build it is inherently unsafe regardless of timeline","confidence_level":"Extremely high confidence that AGI pursuit is inherently unsafe; rejects timeline framing entirely","source_name":"The Stanford Daily","source_url":"https://stanforddaily.com/2023/02/15/utopia-for-whom-timnit-gebru-on-the-dangers-of-artificial-general-intelligence/","concept_keys":["agi"]}