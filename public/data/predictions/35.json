{"tldr_summary":"Oxford philosopher Nick Bostrom and Vincent Müller surveyed hundreds of AI researchers in 2012-2013, producing one of the field's most-cited timeline studies. The results: median prediction gave 50% probability of High-Level Machine Intelligence (HLMI) by 2040-2050, rising to 90% probability by 2075. HLMI was defined as AI that can accomplish most human occupations as well as typical humans—a practical, job-focused definition rather than abstract intelligence. The survey also asked about superintelligence: experts estimated it would arrive within 30 years after HLMI, and gave roughly one-in-three odds that the outcome would be 'bad' or 'extremely bad' for humanity. The 35-year spread between median and high-confidence predictions captures genuine uncertainty—some experts thought decades, others thought generations. Published in 2014, the survey became a reference point for AI safety discussions, showing that concerns about advanced AI weren't fringe paranoia but mainstream expert opinion, even if the experts couldn't agree on when.","criteria_definition":"High-Level Machine Intelligence capable of accomplishing most human occupational tasks","confidence_level":"Median estimates with wide confidence intervals spanning 35 years","source_name":"Future Progress in AI: A Survey of Expert Opinion - Synthese Library (2016)","source_url":"https://nickbostrom.com/papers/survey.pdf","concept_keys":["agi","alignment","survey-drift"]}