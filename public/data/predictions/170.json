{"tldr_summary":"Stuart Russell, the Berkeley professor who literally wrote the textbook on AI, published a stark warning in December 2025: the trillion-dollar race to AGI could replace humans by 2030, and governments are failing to stop it. Russell characterizes the current situation as the 'Gorilla Problem'â€”by creating something more intelligent than ourselves, humans are voluntarily becoming like gorillas, whose survival depends entirely on whether the superior species cares to preserve them. He argues AI doesn't need consciousness or evil intent to destroy us, just superior competence at achieving goals that conflict with human survival. Russell reserves particular criticism for industry leaders like Sam Altman and Elon Musk, who have signed statements acknowledging AGI as an extinction risk yet continue racing toward it anyway. He calls this 'Russian Roulette' driven by greed, suggesting only a nuclear-level AI catastrophe will wake up regulators. Russell's 2030 timeline for transformative AI is notably more aggressive than his earlier 19-year AGI estimate, reflecting growing alarm at the pace of development and absence of safety measures.","criteria_definition":"Transformative AI capable of replacing humans by 2030, developed through reckless corporate race","confidence_level":"High confidence in near-term transformative AI with extinction-level risk; characterizes current trajectory as 'Russian Roulette'","source_name":"Newsweek article (January 2025)","source_url":"https://blog.dragansr.com/2025/12/ai-expert-warning-stuart-russell.html","concept_keys":["transformative-ai","alignment"]}