{"tldr_summary":"JÃ¼rgen Schmidhuber, the Swiss AI pioneer whose LSTM networks power Siri and Alexa, is taking heat for two controversial positions: partnering with Saudi Arabia's futuristic AI initiatives and refusing to sign the 'Pause Gigantic AI Experiments' letter that Elon Musk endorsed. Speaking from his position as former scientific director of IDSIA and founder of Nnaisense, Schmidhuber argues the singularity is coming around 2050 but insists existential AI risk is overblown hype. His reasoning? Different people have different ethics, so who decides what's 'safe'? Meanwhile, he's helping the kingdom fund AI research, arguing the whole world benefits from their investment in what could trigger a new golden age for science. Critics see contradiction: dismissing AI risks while building toward systems that could 'colonize the galaxy.' Schmidhuber's response would likely be that colonizing the galaxy is awesome, actually, and the real risk is letting fear-mongering slow down progress. It's a uniquely optimistic take from someone who's been in the game since before deep learning was cool.","criteria_definition":"Singularity defined as AI systems capable of autonomous space colonization and self-improvement beyond human control.","confidence_level":"Moderate confidence with deliberate pushback against AI existential risk narratives","source_name":"Rest of World interview January 2025","source_url":"https://restofworld.org/2025/juergen-schmidhuber-ai-saudi-arabia-tech/","concept_keys":["event-horizon"]}