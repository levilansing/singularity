{"tldr_summary":"Paul Christiano, the leading AI safety researcher who invented RLHF at OpenAI, assigns 15% probability to transformative AI by 2030 and 40% by 2040. In a candid Dwarkesh Patel interview, he admitted his timelines have 'half a significant figure' of confidence and change constantlyâ€”a refreshing dose of honesty in a field full of false precision. Christiano now leads the Alignment Research Center and works with major labs on responsible scaling policies. His relatively 'modest' timelines (by 2024 standards) reflect deep technical understanding of remaining challenges, though even he acknowledges the uncertainty is massive. The fact that the person who literally taught GPT-4 to be helpful is this uncertain should tell you something about how hard forecasting this stuff really is.","criteria_definition":"Transformative AI capable of fundamentally reshaping society and economy through autonomous capabilities","confidence_level":"Self-described as having 'half a significant figure' of confidence; admits his numbers change frequently","source_name":"Dwarkesh / alignment forum","source_url":"https://www.dwarkesh.com/p/paul-christiano","concept_keys":["transformative-ai","scaling-hypothesis","alignment"]}