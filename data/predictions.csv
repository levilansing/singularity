"predictor_name","predictor_type","prediction_date","predicted_year_low","predicted_year_high","predicted_year_best","prediction_type","confidence_level","criteria_definition","source_name","source_url","headshot_url","headline","tldr_summary","graphic_url"
"John von Neumann","Individual","1950","","","","Singularity","Conceptual","Essential singularity in the history of the race beyond which human affairs could not continue; accelerating technological progress becomes incomprehensible","Ulam tribute in Bulletin of the American Mathematical Society (1958)","https://en.wikipedia.org/wiki/Technological_singularity","https://www.loc.gov/resource/cph.3b24063/","Manhattan Project Mathematician Predicts Humanity's Event Horizon in the 1950s","The polymath who helped build the atomic bomb quietly coined 'singularity' to describe a future where technological change becomes so rapid that human affairs 'could not continue' as we know them. Von Neumann never lived to see computers smaller than refrigerators, but he foresaw the approaching storm.",""
"Herbert A. Simon & Allen Newell","Individual","1958","1968","1985","1968","AGI","Certain","Digital computer as world chess champion within 10 years; machines doing any work a man can do by 1985","Heuristic Problem Solving: The Next Advance in Operations Research (1958)","https://quoteinvestigator.com/2024/04/18/ai-prediction/","https://history.computer.org/pioneers/images/newell.jpg","AI Pioneers Promise Chess Domination by 1968, Total Human Obsolescence by 1985","The duo behind the first AI programs got wildly optimistic in 1958, predicting computers would be chess champions within a decade (they were off by 29 years) and handle any human job by 1985 (still waiting). Their General Problem Solver turned out to be less general than advertised, but their hubris set the template for AI hype cycles to come.",""
"I.J. Good","Individual","1965","1965","2000","2000","Intelligence Explosion","More probable than not","Ultraintelligent machine surpassing all human intellectual activities; recursive self-improvement creating intelligence explosion; last invention man need ever make","Speculations Concerning the First Ultraintelligent Machine - Advances in Computers vol. 6","https://quoteinvestigator.com/2022/01/04/ultraintelligent/","","Codebreaker Warns: Ultraintelligent Machines Will Be 'The Last Invention Man Need Ever Make'","The British mathematician who cracked Nazi codes with Turing imagined a machine that designs better machines in an endless feedback loop. Good called it 'the last invention'—after which, superintelligent AI handles all further innovation. His 1965 essay remains the clearest articulation of recursive self-improvement that terrifies AI safety researchers today.",""
"Marvin Minsky","Individual","1967","1990","2000","1997","AGI","Convinced","Within a generation few compartments of intellect will remain outside the machine's realm; the problem of creating artificial intelligence will be substantially solved","Computation: Finite and Infinite Machines (1967)","https://quoteinvestigator.com/2021/03/04/ai-solved/","https://web.archive.org/web/20160503163720im_/http://web.media.mit.edu/~minsky/marvin.jpg","MIT's Minsky Declares AI 'Substantially Solved' Within 30 Years","The MIT AI lab founder promised in 1967 that within a generation, machines would match human intellect across the board. Minsky spent the next 40 years recalibrating his timeline while watching 'AI winters' freeze funding. He never lost faith that AGI was just around the corner—each corner just turned out to be farther than expected.",""
"Marvin Minsky","Individual","1970","1973","1978","1975","AGI","Certain","A machine with the general intelligence of an average human being","Life Magazine interview (1970)","https://web.eecs.umich.edu/~kuipers/opinions/AI-progress.html","https://web.archive.org/web/20160503163720im_/http://web.media.mit.edu/~minsky/marvin.jpg","Minsky Gives Humanity 3-8 Years Before Machines Match Us","In a bold 1970 Life Magazine interview, Minsky put human-level AI just five years away. When 1975 came and went, AI entered its first major 'winter' as funding dried up and promises went unfulfilled. Minsky's confident prediction became Exhibit A in why the field learned to temper expectations—at least until the 2020s.",""
"Donald Michie Survey","Survey","1973","1993","2023","2023","AGI","Survey median","Human-level computing systems; respondents split between 20 years 50 years and more","Michie survey of British and American computer scientists (1973)","https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-timelines","","1973 Survey Shows AI Experts Split: 20 Years, 50 Years, or Never","British computer scientist Donald Michie polled his peers in the early 1970s and found the field deeply divided on AGI timelines. Some said 1993, some said 2023, some said it was impossible. The median prediction—2023—turned out eerily prescient given ChatGPT's late-2022 arrival, though what counts as 'human-level' remains hotly debated.",""
"Vernor Vinge","Individual","1983","","","","Singularity","Conceptual","Creation of intelligences greater than our own; intellectual transition as impenetrable as the knotted space-time at center of a black hole","First Word - Omni magazine (January 1983)","https://en.wikipedia.org/wiki/Technological_singularity","","Sci-Fi Author Borrows Physics Term to Name AI's Unknowable Future","Science fiction writer Vernor Vinge imported 'singularity' from astrophysics—the point where physics breaks down inside a black hole—to describe the moment when superintelligent AI makes the future fundamentally unpredictable. Vinge's metaphor stuck because it captures both the sudden phase change and our inability to see past it.",""
"Hans Moravec","Individual","1988","2010","2040","2030","AGI","Estimate","Computational capacity matching the human brain (~100 trillion operations/sec); robots evolving into new artificial species; postbiological world of self-improving thinking machines","Mind Children: The Future of Robot and Human Intelligence (1988)","https://en.wikipedia.org/wiki/Hans_Moravec","","Robotics Prof Predicts Machines Will Become 'Our Mind Children' by 2030","Carnegie Mellon roboticist Hans Moravec calculated the brain's computational throughput and predicted we'd match it by 2030, spawning a 'postbiological' world of robot descendants. His book 'Mind Children' painted humans as caterpillars building mechanical butterflies. We hit his compute benchmarks but not his intelligence milestones.",""
"Vernor Vinge","Individual","1993","2005","2030","2023","Singularity","High confidence","Creation of greater than human intelligence signaling end of the human era; four pathways: superhuman AI computers large network awakening brain-computer interfaces biological enhancement","The Coming Technological Singularity - NASA VISION-21 Symposium (1993)","https://edoras.sdsu.edu/~vinge/misc/singularity.html","","Computer Scientist Tells NASA: The Human Era Ends by 2030","Vinge's 1993 NASA presentation became the singularity's founding document, predicting superintelligence between 2005 and 2030 via four routes—AI, networked computers, brain-computer interfaces, or genetic engineering. He centered 2023 as most likely, calling it the 'end of the human era.' His median guess lands awkwardly close to ChatGPT's arrival.",""
"Louis Rosenberg","Individual","1993","2040","2060","2050","Singularity","Estimate","AI exceeding human abilities broadly across domains","Emerj survey of AI researchers","https://emerj.com/when-will-we-reach-the-singularity-a-timeline-consensus-from-ai-researchers/","","VR Pioneer Pencils in Singularity for Mid-Century","Louis Rosenberg, who built the first functional augmented reality system at Air Force Research Lab, put the singularity around 2050—a conservative estimate that aged well compared to peers. His bet: genuine AGI requires breakthroughs we can't yet envision, so hedge toward later dates.",""
"Marvin Minsky","Individual","1994","","","","Singularity","Conceptual","Robots will inherit the Earth; intelligent machines via nanotechnology as human mind children","Will Robots Inherit the Earth? - Scientific American (1994)","https://en.wikipedia.org/wiki/Technological_singularity","https://web.archive.org/web/20160503163720im_/http://web.media.mit.edu/~minsky/marvin.jpg","Minsky in Scientific American: 'Robots Will Inherit the Earth'","After decades of overpromising AGI timelines, an older Minsky went full philosophical in 1994, arguing robots would inevitably supplant humanity through nanotechnology and recursive improvement. He stopped giving dates and started writing our mechanical successors' eulogies.",""
"Nick Bostrom","Individual","1998","2000","2033","2033","Superintelligence","Estimate","Superintelligence: an intellect much smarter than the best human brains in practically every field including scientific creativity general wisdom and social skills","How Long Before Superintelligence? - Journal of Future Studies (1998)","https://nickbostrom.com/superintelligence","https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Nick_Bostrom%2C_Stanford_2006_%28square_crop%29.jpg/440px-Nick_Bostrom%2C_Stanford_2006_%28square_crop%29.jpg","Swedish Philosopher Predicts Superintelligence by 2033, Everyone Panics","Oxford philosopher Nick Bostrom's 1998 paper mapped paths to machine superintelligence, centering his estimate at 2033. His rigorous analysis of recursive self-improvement scenarios launched the 'AI safety' field and convinced some very wealthy people that humanity's survival depends on alignment research.",""
"Hans Moravec","Individual","1998","2040","2050","2040","AGI","Estimate","Computational equivalence to human brain (~10^15 instructions/sec); no job people can do better than robots by 2040","When Will Computer Hardware Match the Human Brain? - Journal of Transhumanism (1998)","https://jetpress.org/volume1/moravec.pdf","","Moravec Doubles Down: 'No Job We Can Do Better' by 2040","Still calculating, still optimistic, Moravec updated his prediction in 1998: by 2040, robots will outperform humans at every job. His methodology—counting neurons and synapses, then mapping to transistors—remains influential even as his timelines slide rightward.",""
"Ray Kurzweil","Individual","1999","2029","2029","2029","AGI","Certain","Machines able to pass the Turing test; $1000 computer equaling computational power of 1000 human brains; Law of Accelerating Returns","The Age of Spiritual Machines (1999)","https://en.wikipedia.org/wiki/The_Age_of_Spiritual_Machines","https://news.mit.edu/sites/default/files/images/202510/Ray%20Kurzweil%20Lecture%20-%202025-10-09%20-%20Wednesday%20-%20Photo%20by%20Gretchen%20Ertl%20-%20MIT.jpg","Kurzweil Stakes Reputation on 2029 AGI, Refuses to Budge for 25 Years","In 1999, futurist Ray Kurzweil planted his flag at 2029 for AGI passing the Turing test, based on exponential compute trends he calls the Law of Accelerating Returns. A quarter-century later, he hasn't moved the date an inch. We're now close enough to find out if his exponential curves were prophetic or wishful thinking.","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTCountdowntoSingularityLog.jpg/1200px-PPTCountdowntoSingularityLog.jpg"
"Ray Kurzweil","Individual","2005","2029","2029","2029","AGI","Certain","AI passes valid Turing test; non-biological intelligence exceeds capacity of all living biological human intelligence by early 2030s","The Singularity Is Near (2005)","https://en.wikipedia.org/wiki/The_Singularity_Is_Near","https://news.mit.edu/sites/default/files/images/202510/Ray%20Kurzweil%20Lecture%20-%202025-10-09%20-%20Wednesday%20-%20Photo%20by%20Gretchen%20Ertl%20-%20MIT.jpg","The Book That Launched A Thousand Podcasts: Kurzweil Says 2029 (Again)","Kurzweil's 2005 opus 'The Singularity Is Near' became the Bible of techno-optimism, predicting AGI by 2029 and full human-AI merger by 2045. Critics call him a prophet, a huckster, or both. His track record on narrow predictions (smartphone ubiquity, computer vision) has been eerily good, lending weight to the big claims.","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTCountdowntoSingularityLog.jpg/1200px-PPTCountdowntoSingularityLog.jpg"
"Ray Kurzweil","Individual","2005","2045","2045","2045","Singularity","Certain","Merger of human technology with human intelligence; machine intelligence becomes infinitely more powerful than all human intelligence combined; Epoch 5","The Singularity Is Near (2005)","https://en.wikipedia.org/wiki/The_Singularity_Is_Near","https://news.mit.edu/sites/default/files/images/202510/Ray%20Kurzweil%20Lecture%20-%202025-10-09%20-%20Wednesday%20-%20Photo%20by%20Gretchen%20Ertl%20-%20MIT.jpg","Futurist Doubles Down on 2045: Your Brain Will Merge With The Cloud Whether You Like It or Not","Google's chief AI prophet maintains his signature 2045 prediction—the year we'll connect our neocortexes to cloud computing via nanobots, multiplying human intelligence a millionfold. Kurzweil's been eerily accurate before, so when he promises immortality through AI merger, people listen. His exponential growth charts suggest we're right on schedule.","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTCountdowntoSingularityLog.jpg/1200px-PPTCountdowntoSingularityLog.jpg"
"AGI-09 Conference Survey","Survey","2009","2030","2070","2050","AGI","Survey median","AGI milestones including passing Turing test accomplishing Nobel-worthy breakthroughs and superhuman intelligence","Baum et al. How long until human-level AI? (2011)","https://sethbaum.com/ac/2011_AI-Experts.pdf","","AGI Conference Attendees Bet on 2050, Give or Take 20 Years","In 2009, researchers gathered for the first AGI conference and surveyed each other on timelines. The median estimate—2050—reflected post-AI-winter caution. The 40-year spread (2030-2070) captured the field's genuine uncertainty about whether AGI is decades or lifetimes away.",""
"David Chalmers","Individual","2010","2050","2300","2100","Singularity","Not implausible","Intelligence explosion: once AI exceeds human intelligence it designs better AI rapidly surpassing all human intellect; even 1% chance in next century warrants preparation","The Singularity: A Philosophical Analysis - Journal of Consciousness Studies (2010)","https://consc.net/papers/singularity.pdf","https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjptfbRCKXvGSImfCy7M84nOsFMfmiFo_pCKo-UJfjT0TjZLJjxQ-7sJLGfmVHG6vV5vWMUb3W8pMQbgz0d0EqMSsjwHGrWiCsYZzn7lDxzIRZ9d6mjRXANh_kqWqM4VXgHhMhLfK5Zxw/s1600/DavidChalmers2.jpg","Consciousness Expert: Intelligence Explosion 'Not Implausible,' Maybe This Century","Philosopher David Chalmers rigorously analyzed singularity scenarios in 2010, concluding that recursive self-improvement wasn't just sci-fi fantasy—it was plausible enough to warrant serious preparation. His range (2050-2300) is wonderfully honest about our ignorance, but he notes even 1% odds matter when extinction's on the table.",""
"Shane Legg","Individual","2011","2025","2035","2028","AGI","50%","Minimal AGI: an artificial agent reliably performing the full range of cognitive tasks of an average human; coined term artificial general intelligence","Multiple interviews and 2008 PhD thesis Machine Super Intelligence","https://edrm.net/2023/11/shane-leggs-vision-agi-is-likely-by-2028-as-soon-as-we-overcome-ais-senior-moments/","https://images.squarespace-cdn.com/content/v1/5f5d3cd28b89b0683b7e3e01/1642430902934-SQIAQZD7DHXW2XRZRBAO/Shane-Legg.jpg","DeepMind Co-Founder Gives 50-50 Odds on AGI by 2028","Shane Legg, who coined the term 'artificial general intelligence' and co-founded DeepMind, put even money on AGI by 2028—back in 2011. His definition: an AI that reliably handles the full range of human cognitive tasks. As we approach his deadline with LLMs showing flashes of brilliance and concerning gaps, his bet looks prescient and premature.",""
"Baum Goertzel & Goertzel","Survey","2011","2030","2100","2050","AGI","Survey range","How long until human-level AI; expert assessment with wide variation","Technological Forecasting and Social Change vol 78 (2011)","https://sethbaum.com/ac/2011_AI-Experts.pdf","","Expert Survey: AGI Somewhere Between 2030 and 2100 (Thanks, That Clears It Up)","This 2011 survey of AI researchers showcased the field's spectacular lack of consensus, with predictions spanning 70 years. The median—2050—suggests experts were hedging their bets after decades of hype cycles. The massive variance tells you more about our ignorance than our knowledge.",""
"Muller & Bostrom Survey","Survey","2013","2040","2075","2045","HLMI","50% by 2040-2050","High-Level Machine Intelligence: one that can carry out most human professions at least as well as a typical human; 50% by 2040 90% by 2075","Future Progress in AI: A Survey of Expert Opinion - Synthese Library (2016)","https://nickbostrom.com/papers/survey.pdf","","Bostrom Surveys Experts: 50% Say HLMI by Mid-Century","Oxford's Nick Bostrom and Vincent Muller surveyed hundreds of AI researchers, finding median predictions of 2040-2050 for 'high-level machine intelligence'—AI that can do most jobs as well as humans. The 90% confidence interval stretched to 2075, capturing genuine uncertainty about whether we're decades or generations away.",""
"Stephen Hawking","Individual","2014","","","","Superintelligence","Warning","Success in creating AI would be the biggest event in human history and might also be the last unless we learn to avoid the risks","Co-authored article with Russell Tegmark and Wilczek (2014)","https://en.wikipedia.org/wiki/Technological_singularity","https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Stephen_Hawking.StarChild.jpg/440px-Stephen_Hawking.StarChild.jpg","Hawking: AI Could Be 'The Last Event in Human History' If We Screw Up","Stephen Hawking co-authored a 2014 essay warning that creating superintelligent AI could be 'the biggest event in human history—and possibly the last' unless we solve alignment. The world's most famous physicist lending his voice to AI safety moved the conversation from fringe to mainstream overnight.",""
"Nick Bostrom","Individual","2014","2040","2100","2050","Superintelligence","Survey-based","Superintelligence: any intellect that greatly exceeds cognitive performance of humans in virtually all domains; once HLMI achieved superintelligence could follow within years to decades","Superintelligence: Paths Dangers Strategies - Oxford University Press (2014)","https://en.wikipedia.org/wiki/Nick_Bostrom","https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Nick_Bostrom%2C_Stanford_2006_%28square_crop%29.jpg/440px-Nick_Bostrom%2C_Stanford_2006_%28square_crop%29.jpg","Oxford Philosopher's 'Superintelligence' Book Terrifies Silicon Valley","Nick Bostrom's 2014 book became the AI safety movement's Rosetta Stone, arguing that once we achieve human-level AI, superintelligence could follow 'within years to decades' through recursive self-improvement. Elon Musk called it a must-read. The book's scenarios—from paperclip maximizers to singleton world governments—haunt every AGI discussion.",""
"Grace et al. Survey","Survey","2016","2025","2090","2061","HLMI","50% within 45 years","HLMI: unaided machines can accomplish every task better and more cheaply than human workers; 352 NIPS/ICML 2015 researchers surveyed; Asian respondents ~30 years North American ~74 years","When Will AI Exceed Human Performance? - JAIR vol 62 (2018)","https://arxiv.org/abs/1705.08807","","2016 Survey Shows Massive East-West Split on AGI: Asia Says 2046, America Says 2089","Katja Grace's landmark 2016 survey of 352 machine learning researchers revealed a shocking geographic divide: Asian researchers predicted AGI 44 years sooner than North Americans. The overall median—2061—represented pre-GPT conventional wisdom that AGI was distant. ChatGPT made those timelines look quaint.",""
"Max Tegmark","Individual","2017","2040","2200","2100","Singularity","Wide uncertainty","Life 3.0: AI that can redesign both its software and hardware; intelligence explosion; considered wide range from decades to over a century","Life 3.0: Being Human in the Age of AI (2017)","https://www.singularityweblog.com/max-tegmark/","https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Max_Tegmark_2012.jpg/440px-Max_Tegmark_2012.jpg","MIT Physicist Admits Radical Uncertainty: AGI Between 2040 and 2200","Max Tegmark's 'Life 3.0' proposed AI that redesigns its own hardware and software, but his timeline stretched from decades to centuries. The 160-year range is refreshingly honest about our ignorance. Tegmark's main message: we need to figure out alignment before we build the thing, whatever decade that happens.",""
"Ross Gruetzemacher Survey","Survey","2018","2040","2118","2068","HLMI","50% before 2068","When AI systems would be capable of performing 99% of tasks for which humans are currently paid","Our World in Data / AI survey analysis","https://ourworldindata.org/ai-timelines","","Survey: AI Will Do 99% of Paid Tasks by 2068 (So Start Planning Your Hobbies)","Ross Gruetzemacher's 2018 survey asked when AI would handle 99% of economically valuable work—a more concrete framing than vague 'human-level' intelligence. The median answer, 2068, suggests experts saw nearly half a century of employment ahead. The upper bound stretching to 2118 captured deep skepticism from some quarters.",""
"Rodney Brooks","Individual","2018","2200","2300","2300","AGI","Deliberately provocative","True AGI; chosen to illustrate the absolute inanity of predicting dates for when we will understand intelligence; does not think LLMs represent a path to AGI","Rodney Brooks blog - AGI Has Been Delayed","https://rodneybrooks.com/predictions-scorecard-2025-january-01/","https://www.roboticsbusinessreview.com/wp-content/uploads/2022/02/RodneyBrooks_credit-TomKates-e1645125706859.jpg","Robotics Pioneer Rodney Brooks Trolls Everyone With 2300 AGI Prediction","iRobot founder and MIT robotics legend Rodney Brooks threw down 2300 as his AGI estimate—deliberately absurd to mock the prediction game. Brooks argues LLMs are fancy pattern matchers, not intelligence, and we're nowhere close to understanding what AGI even means. His message: stop forecasting what you don't comprehend.",""
"Baobao Zhang Survey","Survey","2019","2035","2085","2060","HLMI","50% before 2060","When machines would surpass median human worker in performing over 90% of economically relevant tasks","Forecasting AI Progress survey (arXiv)","https://arxiv.org/abs/2206.04132","","2019 Survey: Machines Will Outperform Humans at 90% of Jobs Before 2060","Baobao Zhang's 2019 survey framed the question economically: when will AI outperform median humans at 90%+ of work tasks? The median answer, 2060, suggested four more decades of job security. The survey came before GPT-3 rewrote everyone's priors about language AI.",""
"Emerj Survey of 32 AI Experts","Survey","2019","2035","2100","2060","Singularity","45% before 2060","When the singularity would occur; 45% predict before 2060 34% after 2060 21% predict never","Emerj AI Research survey","https://emerj.com/when-will-we-reach-the-singularity-a-timeline-consensus-from-ai-researchers/","","32 AI Experts Surveyed: 21% Say Singularity 'Never,' 45% Say Before 2060","Emerj's 2019 poll of AI experts split nearly evenly between 'before 2060' (45%), 'after 2060' (34%), and 'never' (21%)—a tripartite division reflecting fundamental disagreement about whether the singularity is even possible. The 'never' camp remains vocal, arguing intelligence has a ceiling or requires biological substrate.",""
"Elon Musk","Individual","2020-07","2025","2025","2025","AGI","Certain","AI will become vastly smarter than any human and would overtake us by 2025","New York Times interview (July 2020)","https://www.diamandis.com/blog/age-of-abundance-30-human-level-ai","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Elon Musk in 2020: AGI Arrives in 5 Years, Definitely This Time","Musk declared in July 2020 that AI would overtake all humans by 2025. His prediction came before GPT-3's release and years before his own xAI company. Musk's timeline track record is notoriously optimistic—remember 'full self-driving next year' since 2016?—but his 2025 AGI call aged better than expected given 2024's model capabilities.",""
"Ajeya Cotra","Individual","2020","2030","2090","2050","Transformative AI","50% by 2050","Biological anchors framework: compute required to train a model matching the brain; transformative AI based on evolutionary and neural compute estimates","Open Philanthropy Biological Anchors Report (2020)","https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines","","Open Philanthropy Researcher Counts Neurons, Arrives at 2050","Ajeya Cotra's 'biological anchors' approach estimated compute requirements by calculating evolution's total compute bill to produce human brains. Her initial 2050 median for 'transformative AI' became the rationalist community's reference class, grounding speculative timelines in transistor counts. She later moved it up to 2040 as scaling laws exceeded expectations.",""
"David Roodman","Individual","2020","2030","2060","2037","Transformative AI","Modeled estimate","Modeling gross world product to singularity-like growth; GWP hitting infinity implies transformative AI by ~2037","GWP extrapolation model - LessWrong","https://coefficientgiving.org/research/modeling-the-human-trajectory/","","Economist Extrapolates GDP Growth, Finds Economic Singularity by 2037","David Roodman modeled gross world product growth rates over millennia and found the curve approaching infinity around 2037—an 'economic singularity' where automation drives hyperbolic GDP growth. His method treats AGI as inevitable once you fit historical growth curves, though critics note he's fitting a straight line to a very wiggly function.",""
"Holden Karnofsky","Individual","2021","2036","2100","2060","Transformative AI",">10% by 2036 ~50% by 2060","Transformative AI: AI that transforms the economy and world as much as the Industrial Revolution","Cold Takes blog - Where AI Forecasting Stands Today (2021)","https://www.cold-takes.com/where-ai-forecasting-stands-today/","","Open Philanthropy CEO: 10% Chance Civilization Transforms Within 15 Years","Holden Karnofsky, who allocates hundreds of millions to AI safety, put >10% odds on transformative AI by 2036 and ~50% by 2060. His 'Cold Takes' blog series made the case that we're 'radically unprepared' for AI timelines much shorter than conventional wisdom suggested. The kicker: he wrote this before ChatGPT.",""
"Grace et al. Survey","Survey","2022","2035","2090","2059","HLMI","50% by 2059","High-level machine intelligence; updated survey of AI researchers; slight change from 2016 survey","AI Impacts 2022 Expert Survey on Progress in AI","https://wiki.aiimpacts.org/doku.php?id=ai_timelines:predictions_of_human-level_ai_timelines:ai_timeline_surveys:2022_expert_survey_on_progress_in_ai","","2022 Survey Moves AGI Up One Year to 2059 (Yawn)","Katja Grace's 2022 follow-up to her 2016 survey found researchers barely budged: median HLMI shifted from 2061 to 2059. The stability suggested experts weren't updating much on AlphaFold, GPT-3, or DALL-E. Then ChatGPT dropped five months later and scrambled everyone's priors overnight.",""
"Ajeya Cotra","Individual","2022","2030","2070","2040","Transformative AI","50% by 2040","Updated biological anchors framework; moved estimate up a decade from 2050 to 2040 based on observed progress","Open Philanthropy updated report (2022)","https://80000hours.org/2025/03/when-do-experts-expect-agi-to-arrive/","","AI Safety Researcher Watches GPT-3, Pulls AGI Timeline Forward 10 Years","Ajeya Cotra updated her influential 2020 report in 2022, moving her median from 2050 to 2040 based on scaling law progress exceeding expectations. Her revision—a decade closer—foreshadowed the timeline compression that would accelerate dramatically after ChatGPT's public release months later.",""
"Connor Leahy","Individual","2022","2025","2050","2030","AGI","50% by 2030","AGI; all Conjecture employees expected AGI before 2035 as of 2023","YouTube and Conjecture blog","https://www.conjecture.dev/timelines-and-pdoom/","","Alignment Startup CEO: 50-50 Odds AGI Arrives This Decade","Connor Leahy, who founded Conjecture to work on AI alignment, gave even odds on AGI by 2030. His entire company operates under the assumption we have less than a decade to solve alignment before superintelligent systems arrive. That level of urgency—shared across his team—drives the 'race to AGI safety' mentality.",""
"Elon Musk","Individual","2023-07","2028","2029","2029","Superintelligence","Estimate","Digital super intelligence smarter than any human at anything in 5-6 years","Twitter/X Spaces discussion (July 2023)","https://www.diamandis.com/blog/age-of-abundance-30-human-level-ai","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Musk Revises 2020 Prediction, Now Says Superintelligence in 5-6 Years","After his 2025 AGI prediction passed, Musk recalibrated to 2028-2029 for 'digital superintelligence'—AI smarter than any human at everything. This timeline coincides with xAI's Grok development and his massive GPU cluster buildout. Musk's predictions follow a pattern: aggressive, often wrong on exact dates, but directionally prescient.",""
"Geoffrey Hinton","Individual","2023-05","2028","2043","2035","Superintelligence","50% within 20 years","Digital intelligence overtaking us; previously estimated 30-50 years revised sharply downward after leaving Google","X/Twitter post and subsequent interviews (May 2023)","https://x.com/geoffreyhinton/status/1653687894534504451","https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Professor_Geoffrey_Hinton_at_UofT_%28cropped%29.jpg/440px-Professor_Geoffrey_Hinton_at_UofT_%28cropped%29.jpg","'Godfather of AI' Quits Google, Warns Superintelligence May Arrive Within 20 Years","Geoffrey Hinton shocked the AI world by leaving Google in May 2023 to warn about AI risks, slashing his superintelligence timeline from 30-50 years to 5-20 years. The man who won the Turing Award for deep learning breakthroughs now says his life's work might pose existential risk. When the godfather gets nervous, people listen.",""
"Yoshua Bengio","Individual","2023","2028","2043","2035","Superintelligence","95% CI","95% confidence interval for superhuman intelligence at 5 to 20 years; shortened from earlier decades or centuries estimate","FAQ on Catastrophic AI Risks - yoshuabengio.org (2023)","https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/","https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Yoshua_Bengio_-_2017_%28cropped%29.jpg/440px-Yoshua_Bengio_-_2017_%28cropped%29.jpg","Deep Learning Pioneer Bengio Slashes Timeline: 95% Confidence ASI Within 20 Years","Yoshua Bengio, Hinton's fellow Turing Award winner, compressed his superintelligence timeline to 5-20 years with 95% confidence—down from 'decades or centuries' pre-ChatGPT. Bengio's pivot from dismissing AI risk to leading safety research represents the field's dramatic reappraisal of near-term capabilities.",""
"Masayoshi Son","Individual","2023-10","2030","2035","2033","Singularity","Certain","AGI will be 10x more intelligent than all human intelligence combined within a decade; singularity coming in next ten years","SoftBank World corporate conference keynote (October 2023)","https://www.theregister.com/2023/10/09/softbank_ceo_masayoshi_son_ai_vision/","","SoftBank CEO Predicts AGI '10x Smarter Than All Humans Combined' Within a Decade","Billionaire investor Masayoshi Son told SoftBank's annual conference that AGI would be '10x more intelligent than all human intelligence combined' within 10 years. Son, who lost billions on WeWork, now sees AI as civilization's destiny. His prediction came before announcing plans to invest $200B in AI infrastructure.",""
"Shane Legg","Individual","2023","2025","2037","2028","AGI","50% by 2028","Minimal AGI: AI agents capable of handling full range of human cognitive tasks; 80% probability before 2037","DeepMind official podcast (late 2023)","https://80000hours.org/2025/03/when-do-experts-expect-agi-to-arrive/","https://images.squarespace-cdn.com/content/v1/5f5d3cd28b89b0683b7e3e01/1642430902934-SQIAQZD7DHXW2XRZRBAO/Shane-Legg.jpg","DeepMind Co-Founder Stands By 2028 AGI Bet, Adds 80% Confidence by 2037","Shane Legg reiterated his 2011 prediction in late 2023: 50% odds AGI by 2028, 80% by 2037. As DeepMind's chief AGI scientist working on Gemini, Legg has inside knowledge of capability scaling. His consistency across 12 years—while the field whipsawed—lends credibility to the aggressive timeline.",""
"Jurgen Schmidhuber","Individual","2023","2030","2060","2050","Singularity","Estimate","AGI and singularity; noted frequency of notable events appears to approach 21st-century singularity but cautioned about perception bias","Various interviews (~2023)","https://en.wikipedia.org/wiki/Technological_singularity","","LSTM Inventor Warns Singularity Timeline Might Be Perception Bias","Jürgen Schmidhuber, who invented LSTMs (the neural architecture powering early language models), suggested singularity predictions might suffer from temporal parochialism—we think we're special. He noted how the frequency of 'notable events' seems to accelerate, but that's partly our near-sighted view. Still, he puts the singularity mid-century.",""
"Grace et al. Survey (2778 researchers)","Survey","2023-10","2027","2100","2047","HLMI","50% by 2047","HLMI: unaided machines accomplish every task better and more cheaply than human workers; 13-year jump from 2060 in 2022 survey; 10% chance by 2027","Thousands of AI Authors on the Future of AI - arXiv 2401.02843 (2024)","https://arxiv.org/abs/2401.02843","","Post-ChatGPT Survey Shocks Everyone: AGI Median Leaps From 2060 to 2047","In the most dramatic timeline shift ever recorded, Katja Grace's 2023 survey of 2,778 AI researchers moved the median HLMI prediction from 2060 to 2047—a 13-year jump in just one year. ChatGPT's emergence scrambled the field's priors overnight. The survey also gives 10% odds to AGI by 2027, injecting urgency into safety debates.",""
"Daniel Kokotajlo","Individual","2023","2025","2030","2027","Transformative AI","Median estimate","Transformative AI; radical transformation and automation of economy","LessWrong discussion and AI 2027 project","https://ai-2027.com/","","Former OpenAI Governance Researcher Quits, Predicts TAI by 2027","Daniel Kokotajlo left OpenAI's governance team in 2023 and launched 'AI 2027'—a project centered on transformative AI arriving within 4 years. His insider perspective from OpenAI, combined with his public departure over safety concerns, lends weight to the aggressive timeline. Kokotajlo argues companies are racing toward capabilities nobody can control.",""
"Paul Christiano","Individual","2023","2028","2045","2033","Transformative AI","30% by 2033","Transformative AI: AI that transforms the economy and world as much as the Industrial Revolution","EA Forum and LessWrong","https://forum.effectivealtruism.org/posts/SYtwChBTs6xkocBSP/when-do-experts-think-human-level-ai-will-be-created","","Alignment Researcher Gives 30% Odds Economy Transforms by 2033","Paul Christiano, who led alignment research at OpenAI before founding the Alignment Research Center, gives 30% probability to transformative AI by 2033. His focus on 'slow takeoff' scenarios—where AI gradually automates research rather than explosively recursive improvement—colors his more measured (but still aggressive) timeline.",""
"Samotsvety Forecasting","Survey","2023-01","2028","2100","2041","AGI","50% by 2041","AGI broadly defined using Metaculus-like definition; 8 elite forecasters; ~28% chance by 2030","EA Forum - Samotsvety AGI Timelines","https://80000hours.org/2025/03/when-do-experts-expect-agi-to-arrive/","","Elite Forecasters Give 28% Chance AGI Arrives by 2030","Samotsvety, a superforecasting team with track records on prediction markets, put their collective estimate at 50% AGI by 2041 and 28% by 2030. These are professional predictors, not researchers with institutional biases. Their relatively short timelines (compared to pre-2022 surveys) reflect post-ChatGPT recalibration even among prediction specialists.",""
"Ege Erdil","Individual","2023","2040","2120","2073","Transformative AI","Median estimate","Transformative AI; more conservative than most forecasters","LessWrong discussion","https://forum.effectivealtruism.org/posts/SYtwChBTs6xkocBSP/when-do-experts-think-human-level-ai-will-be-created","","Superforecaster Bucks Trend: TAI Not Until 2073","Ege Erdil, a top forecaster on Metaculus and other platforms, stands against the tide with a 2073 median for transformative AI. His contrarian view argues that most forecasters are anchoring on exponential extrapolations that ignore diminishing returns and fundamental barriers. Someone has to be the skeptic.",""
"Elon Musk","Individual","2024-04","2025","2026","2025","AGI","Probable","AGI probably by 2025 within two years; smarter than the smartest human","Interview with Norway sovereign wealth fund CEO (April 2024)","https://www.business-standard.com/technology/tech-news/elon-musk-says-ai-will-gain-general-intelligence-outsmart-humans-by-2025-124040900177_1.html","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Musk Tells Norway's Sovereign Wealth Fund: AGI 'Probably' Next Year","In April 2024, Musk told Norway's $1.6 trillion sovereign wealth fund that AGI would probably arrive within two years. The boldness of predicting AGI by 2025—just months away—underscores Musk's conviction that xAI's Grok and competitors are on the cusp. Or his perennial overoptimism. Probably both.",""
"Elon Musk","Individual","2024-05","2025","2025","2025","AGI","Certain","When asked how long until AGI replied next year","X post replying to Logan Kilpatrick (May 2024)","https://www.gizmodo.com/elon-musk-says-ai-will-be-smarter-than-the-smartest-human-by-next-year-2000481050","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Elon Musk, Master of Understatement: 'AGI Next Year'","When asked on X how long until AGI, Musk replied 'next year' in May 2024, pinning AGI to 2025. His casual certainty contrasts with most experts' probabilistic hedging. Musk's pattern: predict the impossible on aggressive timelines, miss the date, hit something directionally close, declare victory, repeat.",""
"Jensen Huang","Individual","2024-03","2027","2031","2029","AGI","Estimate","AI that can pass every human test (bar exam medical exams logic tests) and perform 8% better than most people in 5 years","GTC Conference and Stanford Economic Forum (March 2024)","https://techcrunch.com/2024/03/19/agi-and-hallucinations/","https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Nvidia_CEO_Jensen_Huang_%2851035971662%29_%28cropped%29.jpg/440px-Nvidia_CEO_Jensen_Huang_%2851035971662%29_%28cropped%29.jpg","Nvidia CEO: AGI in 5 Years If You Define It Right (And I Do)","Jensen Huang told Stanford that AGI could arrive in 5 years if defined as AI passing every human test—bar exams, medical boards, logic tests—performing 8% better than most people. His definition is narrower than most (excludes common sense, embodiment), but pragmatic. Huang's selling the shovels in the gold rush, so his optimism is, shall we say, financially aligned.",""
"Ben Goertzel","Individual","2024-03","2027","2032","2029","AGI","Estimate","Human-level AGI capable of self-improvement and introspection leading to intelligence explosion and ASI; possibly as early as 2027","Beneficial AGI Summit Panama City (March 2024)","https://www.livescience.com/technology/artificial-intelligence/ai-agi-singularity-in-2027-artificial-super-intelligence-sooner-than-we-think-ben-goertzel","https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Ben_Goertzel_by_Christopher_Michel_02.jpg/440px-Ben_Goertzel_by_Christopher_Michel_02.jpg","AGI Researcher Who's Been Predicting 2029 Since 2010 Moves It Up to 2027","Ben Goertzel, who's been predicting AGI around 2029 for over a decade, moved his estimate to 'possibly as early as 2027' at the 2024 Beneficial AGI Summit. The SingularityNET founder expects rapid takeoff to ASI once AGI is achieved. His consistency—and his slight acceleration—suggest conviction, not hype-chasing.",""
"Leopold Aschenbrenner","Individual","2024-06","2026","2029","2027","AGI","Strikingly plausible","AGI capable of performing the work of an AI researcher; general-purpose AI rivaling human-level intelligence","Situational Awareness report (June 2024)","https://situational-awareness.ai/wp-content/uploads/2024/06/situationalawareness.pdf","","Former OpenAI Superalignment Researcher Leaks 165-Page 'Situational Awareness' Manifesto","Leopold Aschenbrenner, fired from OpenAI's superalignment team, released a 165-page essay arguing AGI by 2027 is 'strikingly plausible' based on his inside knowledge of scaling trends. His memo describes AI researchers automating themselves, then superintelligence shortly after. The report went viral, terrifying some and galvanizing others toward AGI racing.",""
"Andrew Critch","Individual","2024","2025","2028","2026","AGI","45% by end 2026","AGI broadly defined","X/Twitter post and EA Forum discussion (2024)","https://forum.effectivealtruism.org/posts/SYtwChBTs6xkocBSP/when-do-experts-think-human-level-ai-will-be-created","","AI Safety Researcher Gives 45% Odds AGI Arrives Within 2 Years","Andrew Critch, who works on cooperative AI at UC Berkeley, put 45% probability on AGI by end of 2026—among the most aggressive timelines from any safety researcher. His rationale centers on autoregressive transformers already showing general reasoning, with capability gains compounding faster than most anticipated.",""
"Francois Chollet","Individual","2024","2038","2048","2043","AGI","Estimate","Human-level AI; skeptical of current LLM path; creator of ARC benchmark for measuring general intelligence","EA Forum discussion (~2024)","https://forum.effectivealtruism.org/posts/xkNjpGNfnAYmkFz3s/on-january-1-2030-there-will-be-no-agi-and-agi-will-still","","Keras Creator and AGI Skeptic: Current Path Won't Get Us There Before 2040s","François Chollet, creator of Keras and the ARC benchmark for general intelligence, argues LLMs are sophisticated memorization engines, not genuine intelligence. His timeline—2038-2048—reflects skepticism that scaling alone solves abstraction, reasoning, and generalization. Chollet's ARC benchmark remains unsolved even by frontier models, supporting his 'we're not close' thesis.",""
"Yann LeCun","Individual","2024","2035","2060","2045","AGI","Skeptical","AGI requires world models self-supervised learning and cognitive architectures that current LLMs lack; proposes Advanced Machine Intelligence instead of AGI; decades away","AI Business and CNBC interviews (2024)","https://aibusiness.com/responsible-ai/lecun-debunks-agi-hype-says-it-is-decades-away","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Yann_LeCun_-_2018_%28cropped%29.jpg/440px-Yann_LeCun_-_2018_%28cropped%29.jpg","Meta's Chief AI Scientist Dismisses AGI Hype: 'Decades Away, Maybe Never Via LLMs'","Yann LeCun, Meta's chief AI scientist and another Turing Award winner, calls current AGI hype 'complete BS,' arguing LLMs lack world models and true understanding. He proposes 'Advanced Machine Intelligence' instead, estimates decades away, and doubts autoregressive transformers will ever get us there. LeCun's the industry's highest-profile AGI skeptic.",""
"Dario Amodei","Individual","2024-10","2026","2035","2027","Superintelligence","As early as 2026","Powerful AI model exceeding Nobel Prize winners across most disciplines; as early as 2026 though could take much longer","Machines of Loving Grace essay (October 2024)","https://www.darioamodei.com/essay/machines-of-loving-grace","https://techcrunch.com/wp-content/uploads/2024/10/Dario-Amodei-anthropic.jpeg","Anthropic CEO Pens 15,000-Word Love Letter to AI, Predicts Superintelligence by 2026","Dario Amodei's essay 'Machines of Loving Grace' argues superintelligence could arrive 'as early as 2026'—AI surpassing Nobel laureates across most fields. The Anthropic CEO's timeline shocked even optimists, though he hedged with 'could take much longer.' His techno-utopian vision assumes alignment succeeds, a bet his company's $7B in funding suggests others share.","https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1c502ea9f4a40aa235db9d3d4a1f8f0a-3900x2600.png&w=3840&q=75"
"Dario Amodei","Individual","2024-12","2026","2028","2027","AGI","High confidence","PhD-level and then Nobel-level performance across domains; rapidly running out of truly convincing blockers","Lex Fridman Podcast episode 452 (late 2024)","https://lexfridman.com/dario-amodei-transcript/","https://techcrunch.com/wp-content/uploads/2024/10/Dario-Amodei-anthropic.jpeg","Anthropic CEO on Lex Fridman: 'Running Out of Blockers' to AGI by 2027","Dario Amodei told Lex Fridman we're 'rapidly running out of truly convincing blockers' to AGI, estimating 2026-2028 for systems with PhD-level, then Nobel-level performance across domains. His confidence stems from Anthropic's internal scaling roadmaps. When the CEO of the company with the most compute says we're out of blockers, it's time to pay attention.","https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1c502ea9f4a40aa235db9d3d4a1f8f0a-3900x2600.png&w=3840&q=75"
"Sam Altman","Individual","2024-09","2030","2038","2032","Superintelligence","Possible","Superintelligence in a few thousand days; AI vastly smarter than humans; deep learning worked got predictably better with scale","The Intelligence Age - personal blog (September 23 2024)","https://ia.samaltman.com/","https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg/440px-Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg","OpenAI Boss Counts Down 'Few Thousand Days' Until Machines Outsmart Everyone","Sam Altman's doing math in public: a few thousand days is roughly 8 years, putting superintelligence around 2032. The OpenAI CEO insists deep learning's exponential gains aren't slowing, they're accelerating. His blog post reads like a love letter to the 'Intelligence Age'—promising to cure disease, expand human knowledge, and lift everyone out of poverty. Critics note he's selling tickets to a show that might be a mirage.","https://ia.samaltman.com/img/intelligence-age-header.png"
"Sam Altman","Individual","2024-12","2027","2031","2029","AGI","Estimate","Highly autonomous system that outperforms humans at most economically valuable work; OpenAI definition of AGI","Reddit AMA and interviews (late 2024)","https://www.windowscentral.com/software-apps/sam-altman-claims-agi-will-whoosh-by-in-5-years-with-surprisingly-little-societal-change-while-anthropic-ceo-predicts-a-2026-or-2027-breakthrough-theres-no-ceiling-below-the-level-of-humans-theres-a-lot-of-room-at-the-top-for-ais","https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg/440px-Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg","Altman Predicts AGI 'Will Whoosh By' With 'Surprisingly Little' Societal Change","Sam Altman told Reddit AGI will arrive by 2029 and 'whoosh by' with less disruption than expected—a deliberate counter to doomsday narratives. OpenAI defines AGI as systems outperforming humans at 'most economically valuable work,' a bar that sidesteps harder questions about consciousness and understanding. The framing positions OpenAI's commercial products as the AGI everyone's been waiting for.",""
"Ray Kurzweil","Individual","2024","2029","2029","2029","AGI","Certain","Reaffirmed: machines matching what an expert in every field can do all at the same time; valid Turing test passed","The Singularity Is Nearer book and TED Talk (2024)","https://www.popularmechanics.com/science/a70171717/2045-singularity-ray-kurzweil-predictions/","https://news.mit.edu/sites/default/files/images/202510/Ray%20Kurzweil%20Lecture%20-%202025-10-09%20-%20Wednesday%20-%20Photo%20by%20Gretchen%20Ertl%20-%20MIT.jpg","76-Year-Old Kurzweil Publishes 'The Singularity Is Nearer,' Still Says 2029","Ray Kurzweil's 2024 book reaffirmed everything from his 2005 opus: AGI in 2029, singularity in 2045, human-AI merger through nanobots. At 76, he's doubling down on predictions made when he was 57. His Law of Accelerating Returns charts still show humanity right on schedule. We're now five years out from finding out if the futurist was prophetic or delusional.","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTCountdowntoSingularityLog.jpg/1200px-PPTCountdowntoSingularityLog.jpg"
"Ray Kurzweil","Individual","2024","2045","2045","2045","Singularity","Certain","Reaffirmed: merger of human and machine intelligence; millionfold intelligence amplification through brain nanobots; sticking with 2045","The Singularity Is Nearer book and Science Friday interview (2024)","https://www.popularmechanics.com/science/a70171717/2045-singularity-ray-kurzweil-predictions/","https://news.mit.edu/sites/default/files/images/202510/Ray%20Kurzweil%20Lecture%20-%202025-10-09%20-%20Wednesday%20-%20Photo%20by%20Gretchen%20Ertl%20-%20MIT.jpg","Kurzweil Reaffirms 2045 Human-AI Merger: Nanobots in Your Neocortex, Immortality Included","In 2024 interviews promoting 'The Singularity Is Nearer,' Kurzweil stood firm on 2045 for full human-AI merger via neural nanobots connecting our brains to the cloud. He promises millionfold intelligence expansion, effective immortality through medical nanotech, and transcendence of biological limits. The pitch hasn't changed in 20 years—just the distance to the goalpost.","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTCountdowntoSingularityLog.jpg/1200px-PPTCountdowntoSingularityLog.jpg"
"Masayoshi Son","Individual","2024-06","2027","2029","2028","AGI","Certain","AGI 1-10x smarter than humans in 3-5 years; his lifes purpose is to realize ASI","SoftBank Annual General Meeting (June 2024)","https://www.cnbc.com/2024/06/21/softbank-ceo-masayoshi-son-sees-agi-arriving-in-three-to-five-years.html","","Eccentric Billionaire Declares Realizing ASI His 'Life's Purpose,' Bets on 2028","Masayoshi Son told SoftBank shareholders that achieving artificial superintelligence is 'my life's purpose' and AGI will arrive in 3-5 years. The man who turned $20M into $100B (then lost most of it on WeWork and bad tech bets) now sees AI as his redemption arc. His $100B+ AI infrastructure plans suggest he's putting his money where his messianic vision is.",""
"Masayoshi Son","Individual","2024-10","2032","2036","2034","Superintelligence","Certain","Artificial Superintelligence 10000x smarter than humans in about a decade","Future Investment Initiative Saudi Arabia (October 2024)","https://www.theregister.com/2024/10/29/softbank_super_ai/","","SoftBank CEO Ups The Ante: ASI Will Be 10,000x Smarter Than All Humans","Masayoshi Son told Saudi investors that Artificial Superintelligence—10,000 times smarter than any human—would arrive 'in about a decade.' His previous prediction was AGI 10x smarter in 3-5 years. Son's escalating multipliers (10x, then 10,000x) suggest exponential expectations that make Ray Kurzweil look conservative.",""
"Gary Marcus","Individual","2024","2060","2100","2080","AGI","Skeptical","Flexible general AI with resourcefulness and reliability comparable to human intelligence; challenged Musk 2029 AGI prediction with $100K bet; not near-term","Marcus on AI Substack (2024-2025)","https://garymarcus.substack.com/p/agi-will-not-happen-in-your-lifetime","https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Gary_Marcus_by_Gage_Skidmore.jpg/440px-Gary_Marcus_by_Gage_Skidmore.jpg","NYU Professor Bets $100K Against Musk: AGI Not In Your Lifetime","Cognitive scientist Gary Marcus became AI's loudest skeptic, betting $100,000 against AGI by 2029 and arguing it won't arrive in our lifetimes. Marcus says LLMs are 'unreliable plagiarism machines' that hallucinate and lack true reasoning. His 2060-2100 estimate assumes entirely new architectures—not scaled-up transformers—will be required.",""
"Tom Davidson","Individual","2024","2027","2100","2040","Transformative AI","Best guess 2040","Full automation of labor via compute-centric framework; aggressive preset 100% automation in 2027 conservative preset never","Open Philanthropy takeoff speeds model - Alignment Forum","https://www.alignmentforum.org/posts/Gc9FGtdXhK9sCSEYu/what-a-compute-centric-framework-says-about-ai-takeoff","","Open Philanthropy Modeler's Compute Framework: Labor Automation by 2040","Tom Davidson's 'compute-centric framework' model for Open Philanthropy uses compute scaling trends to forecast labor automation. His 'best guess' lands at 2040 for full automation, though his model's aggressive preset hits 2027 and conservative preset says 'never.' The model treats AGI as compute-determined—controversial but rigorous.",""
"Patrick Winston","Individual","2014","2035","2045","2040","AGI","Estimate","AGI; emphasized it is tough to estimate but believed it would occur","AIMultiple analysis","https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/","","MIT AI Lab's Winston: AGI 'Tough to Estimate,' Guesses 2040","Patrick Winston, longtime director of MIT's AI Lab, gave 2040 as a rough estimate while acknowledging the prediction's difficulty. Winston passed away in 2019, so his 2014 timeline represents pre-deep-learning-boom thinking—AGI was still 25+ years out in conventional wisdom.",""
"Robin Hanson","Individual","2016","2035","2100","2050","Singularity","Speculative","Brain emulations (ems) may arrive before traditional AGI; Age of Em lasting 1-2 human years before superintelligent AI; economy doubling quarterly to weekly","The Age of Em - Oxford University Press (2016)","https://en.wikipedia.org/wiki/Technological_singularity","","Economist Predicts 'Age of Em': Brain Uploads Before AGI, Economy Doubles Weekly","Robin Hanson's 2016 book 'The Age of Em' proposes an alternate path to singularity: whole brain emulation arrives first, creating an 'em economy' doubling every few months that lasts 1-2 subjective years before AI supersedes it. Hanson's detailed em society—billions of copies of productive humans working at accelerated speeds—is futurism's most elaborate tangent.",""
"Sam Altman","Individual","2025-01","2025","2030","2027","AGI","Confident","We are now confident we know how to build AGI as we have traditionally understood it; turning attention to superintelligence","Personal blog post reported by TIME Magazine (January 2025)","https://time.com/7205596/sam-altman-superintelligence-agi/","https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg/440px-Sam_Altman_TechCrunch_SF_2019_-_cropped.jpg","Altman's Stunning Pivot: 'We Know How to Build AGI,' Now Working on Superintelligence","In January 2025, Sam Altman declared OpenAI 'now confident we know how to build AGI as we have traditionally understood it' and announced the company's pivot to superintelligence research. The statement implies AGI is essentially solved—just needs execution—and the real challenge is ASI alignment. Reactions ranged from 'he's seen the scaling curves' to 'classic overpromising.'",""
"Dario Amodei / Anthropic","Individual","2025-03","2026","2027","2027","AGI","Company position","Intellectual capabilities matching or exceeding Nobel Prize winners across most disciplines; a country of geniuses in a datacenter","Anthropic OSTP submission for AI Action Plan (March 2025)","https://www.lesswrong.com/posts/gabPgK9e83QrmcvbK/what-s-up-with-anthropic-predicting-agi-by-early-2027-1","https://techcrunch.com/wp-content/uploads/2024/10/Dario-Amodei-anthropic.jpeg","Anthropic Officially Tells White House: Nobel-Level AI by Early 2027","Anthropic submitted a formal policy document to the White House predicting 'powerful AI' matching Nobel Prize winners across most fields by early 2027. Calling it 'a country of geniuses in a datacenter,' the company's official position—not just CEO musings—commits to an 18-month timeline for superhuman research automation. That's aggressive even by 2025 standards.","https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1c502ea9f4a40aa235db9d3d4a1f8f0a-3900x2600.png&w=3840&q=75"
"AAAI Presidential Panel","Survey","2025","","","","AGI","76% skeptical of scaling","76% of 475 respondents said scaling current AI approaches is unlikely to lead to AGI","AAAI 2025 Presidential Panel Report","https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-Digital-3.7.25.pdf","https://aaai.org/wp-content/uploads/2021/06/AAAI-Logo.svg","Academic AI Society Throws Cold Water on AGI Hype: 76% Say Scaling Won't Work","The Association for the Advancement of Artificial Intelligence surveyed 475 researchers and found 76% believe scaling current architectures won't achieve AGI. The result represents a massive disconnect between industry (scaling is working!) and academia (fundamental breakthroughs needed). The survey's timing—amid peak AGI hype—makes the skepticism especially striking.",""
"Eric Schmidt","Individual","2025-04","2028","2030","2029","AGI","Estimate","AGI based on combining AI progress in reasoning programming and mathematics within 3-5 years","AIMultiple reporting (April 2025)","https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/","https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Eric_Schmidt_2023_crop.jpg/440px-Eric_Schmidt_2023_crop.jpg","Former Google CEO Eric Schmidt: AGI in 3-5 Years by Combining Current Systems","Eric Schmidt, former Google CEO turned AI investor, predicts AGI in 3-5 years by integrating progress in reasoning, programming, and mathematics. Schmidt's bet is that we don't need new breakthroughs—just smart combination of existing capabilities. His timeline coincides with his firm's massive AI investments.",""
"Masayoshi Son","Individual","2025-02","2026","2027","2027","AGI","Certain","AGI arriving much earlier than his previous 2-3 year estimate; machine intelligence surpassing human intelligence","SoftBank enterprise event Tokyo (February 2025)","https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/","","Masa Son Accelerates Timeline Again: AGI Now Expected by 2027","Masayoshi Son revised his already aggressive timeline even shorter in February 2025, moving AGI from 2028 to 2027. The serial reviser shows a pattern: make bold prediction, see capability progress, move prediction even closer. Son's constant timeline compression either shows adaptive forecasting or chronic overoptimism.",""
"Matthew Barnett / Epoch AI","Individual","2025","2028","2045","2033","Transformative AI","Median estimate","Transformative AI based on extrapolating training loss trends via direct approach model","Epoch AI blog - Direct Approach Interactive Model (Q1 2025)","https://epoch.ai/blog/direct-approach-interactive-model","","Epoch AI Extrapolates Training Loss: TAI by 2033","Matthew Barnett and Epoch AI built a model that extrapolates training loss improvements to predict when we hit transformative AI. Their 'direct approach' model—forecasting AI milestones from compute and data scaling—gives a median of 2033. The methodology treats TAI as inevitable given sufficient compute, a view increasingly popular as scaling laws hold.",""
"MIT Report","Survey","2025-08","2026","2047","2028","AGI","50% by 2028 for early milestones","Early AGI-like systems 2026-2028; 50% probability of generalized milestones by 2028; machines surpassing humans in all economically valuable tasks by ~2047","MIT Technology Review - The Road to AGI (August 2025)","https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR_ArmEBrief_V12_final.pdf","https://cdn.technologyreview.com/static/logos/mit-technology-review-logo.svg","MIT Tech Review Maps AGI Timeline: Early Systems by 2026, Full AGI by 2047","MIT Technology Review's comprehensive August 2025 report synthesized expert opinions, finding 50% probability of early AGI-like systems by 2028 and full human-surpassing capability across all economically valuable tasks around 2047. The bimodal distribution—near-term weak AGI, longer-term strong AGI—captures the field's split on definitions.",""
"AI Frontiers","Survey","2025","2026","2032","2028","AGI","50% by 2028","Quantitative AGI definition measuring 10 cognitive abilities; GPT-4 scored 27% GPT-5 scored 57%","AI Frontiers - AGIs Last Bottlenecks","https://ai-frontiers.org/articles/agis-last-bottlenecks","","Researchers Define AGI Quantitatively: GPT-4 Is 27% There, GPT-5 Hits 57%","AI Frontiers built a quantitative AGI benchmark across 10 cognitive abilities. GPT-4 scored 27%, GPT-5 scored 57%, suggesting we're past halfway on their scale. Extrapolating the trajectory, they forecast 50% odds of AGI by 2028. The quantitative approach sidesteps definitional debates by just measuring progress on concrete tasks.",""
"AI 2027 Project","Individual","2025","2027","2028","2027","Superintelligence","Modal estimate","Superhuman coder to AGI to ASI chain; AIs improve from research engineer level to eclipsing all humans at all tasks over 2027","AI 2027 (Kokotajlo et al.)","https://ai-2027.com/","","'AI 2027' Project Maps Superintelligence Cascade Over Next 24 Months","A group of researchers led by Daniel Kokotajlo launched 'AI 2027'—a detailed scenario where superhuman coding AI (2026-2027) rapidly enables AGI, which then automates AI research itself, triggering recursive improvement to ASI by end of 2027. The project treats 2027 as humanity's last 'normal' year before intelligence explosion.",""
"Andrew Ng","Individual","2025-11","2045","2080","2060","AGI","Skeptical","AGI is many decades away maybe even longer; proposed Turing-AGI Test in Jan 2026 measuring multi-day real-world work performance; warns AGI hype misleads investors and students","DeepLearning.AI The Batch newsletter and X/Twitter","https://blockchain.news/flashnews/andrew-ng-agi-is-decades-away-application-layer-ai-won-t-be-wiped-out-soon-and-2025-trading-takeaways-for-ai-stocks-and-crypto","https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Andrew_Ng_IMechE_2021_%28cropped%29.jpg/440px-Andrew_Ng_IMechE_2021_%28cropped%29.jpg","Coursera Co-Founder Andrew Ng Slams AGI Hype: 'Decades Away, Maybe Longer'","Machine learning pioneer Andrew Ng emerged as a prominent AGI skeptic in 2025, arguing claims of imminent AGI 'mislead students, investors, and CEOs.' He proposed a 'Turing-AGI Test' measuring multi-day real-world work performance, which no current system passes. His decades-away estimate pushes back on the 2027-2030 consensus building in industry.",""
"Geoffrey Hinton","Individual","2025-08","2030","2045","2035","Superintelligence","Reasonable bet","AI achieving superintelligence sometime between 5 and 20 years; 10-20% chance of it wiping out humanity","CNN Business reporting on Ai4 conference Las Vegas (August 2025)","https://www.cnn.com/2025/08/13/tech/ai-geoffrey-hinton","https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Professor_Geoffrey_Hinton_at_UofT_%28cropped%29.jpg/440px-Professor_Geoffrey_Hinton_at_UofT_%28cropped%29.jpg","Hinton Refines Doomsday Clock: Superintelligence in 5-20 Years, 10-20% Extinction Risk","In August 2025, Geoffrey Hinton updated his timeline to 5-20 years for superintelligence and attached a 10-20% probability to human extinction. The Nobel Prize winner's willingness to quantify existential risk—and his continued warnings despite backlash—lend gravity to concerns many dismiss as sci-fi panic.",""
"Daniel Kokotajlo","Individual","2025-08","2027","2035","2029","Transformative AI","Updated median","Updated median for transformative AI from 2027 to 2029 as of August 2025","80000 Hours review","https://80000hours.org/2025/03/when-do-experts-expect-agi-to-arrive/","","Ex-OpenAI Researcher Moves TAI Timeline Back Two Years After Seeing Recent Progress","Daniel Kokotajlo updated his median transformative AI estimate from 2027 to 2029 in August 2025—a rare timeline extension amid the compression trend. His revision suggests recent capability gains undershot his expectations, leading to recalibration. Even AGI accelerationists occasionally pump the brakes when reality underperforms models.",""
"Louis Rosenberg","Individual","2024","2028","2032","2030","Singularity","Revised estimate","Singularity: AI surpassing human intelligence broadly; revised from earlier ~2050 estimate","AIMultiple analysis","https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/","","VR Pioneer Revises 2050 Estimate to 2030 After Watching GPT-4","Louis Rosenberg, who originally predicted singularity around 2050, pulled his estimate 20 years closer to 2030 after observing post-2020 AI progress. His revision—from conservative skeptic to median optimist—exemplifies the field-wide timeline compression following the GPT revolution.",""
"Elon Musk","Individual","2026-01","2026","2026","2026","AGI","Engineering calculation","AGI in 2026 as engineering calculation not prophecy; AI smarter than any individual human by end of 2026","Moonshots podcast with Peter Diamandis (January 7 2026)","https://www.nextbigfuture.com/2026/01/elon-musk-expects-true-agi-in-2026-2027-and-superintelligence-about-2030.html","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Musk Calls AGI for 2026: 'It's an Engineering Calculation, Not a Prophecy' (But Also Kind of a Prophecy)","Tesla's CEO-slash-everything says AGI arrives this year—not as wild speculation but as cold, hard engineering math. The man who promised Mars colonies by 2024 and self-driving cars by 2020 now pegs machine superintelligence at 2030. His track record on timelines is, shall we say, optimistic. But he's putting billions behind it with xAI's Grok, so someone believes him.","https://pbs.twimg.com/media/GhKr-NqW0AAlTvF?format=jpg"
"Elon Musk","Individual","2026-01","2030","2031","2030","Superintelligence","Estimate","AI collective intelligence exceeding all humanity within 5 years; 3-7 year bumpy transition period","Moonshots podcast and Davos interview (January 2026)","https://www.nextbigfuture.com/2026/01/elon-musk-expects-true-agi-in-2026-2027-and-superintelligence-about-2030.html","https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Elon_Musk_Royal_Society_%28crop2%29.jpg/440px-Elon_Musk_Royal_Society_%28crop2%29.jpg","Musk Predicts 'Bumpy' 3-7 Year Transition to AI Superintelligence by 2030","Elon Musk outlined a 2026-2030 timeline for the full AGI-to-superintelligence transition, calling it a '3-7 year bumpy transition period.' His framing—acknowledging turbulence—tempers utopian narratives while maintaining aggressive timelines. Musk positions xAI as racing to build aligned ASI before others build unaligned versions.",""
"Dario Amodei","Individual","2026-01","2026","2028","2027","Superintelligence","High confidence","Nobel-level AI in 2 years; software engineers replaced in 6-12 months; superintelligent AGI emerging late 2026 or 2027","World Economic Forum Davos and The Adolescence of Technology essay (January 2026)","https://fortune.com/2026/01/23/deepmind-demis-hassabis-anthropic-dario-amodei-yann-lecun-ai-davos/","https://techcrunch.com/wp-content/uploads/2024/10/Dario-Amodei-anthropic.jpeg","Anthropic CEO Declares Coders Extinct by Christmas, Nobel-Level AI by 2027","Dario Amodei just put a timer on software engineering careers: 6-12 months until AI does it better. The Anthropic chief predicts 'a country of geniuses in a datacenter' by late 2027—systems matching Nobel Prize winners across most fields. His essay drips with urgency about racing to build aligned superintelligence before someone builds the unaligned kind. Expect sleepless nights in Silicon Valley.","https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1c502ea9f4a40aa235db9d3d4a1f8f0a-3900x2600.png&w=3840&q=75"
"Demis Hassabis","Individual","2026-01","2028","2035","2030","AGI","50% by ~2030","50% probability of AGI by ~2030; 5 to 10 years; maybe one or two more breakthroughs needed; more cautious than Amodei","World Economic Forum Davos (January 2026)","https://fortune.com/2026/01/23/deepmind-demis-hassabis-anthropic-dario-amodei-yann-lecun-ai-davos/","https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Demis_Hassabis_Royal_Society.jpg/440px-Demis_Hassabis_Royal_Society.jpg","DeepMind CEO Hassabis at Davos: 50% Odds AGI by 2030, 'One or Two Breakthroughs' Needed","Demis Hassabis offered the most measured timeline among AI CEOs at Davos 2026, giving 50% probability to AGI around 2030 and noting 'one or two more breakthroughs' are needed. The Nobel laureate's caution contrasts with Amodei's 2027 certainty, suggesting even frontier lab leaders disagree on how close we are. Hassabis knows something: AlphaGo, AlphaFold, and Gemini came from his lab.",""
"Metaculus Community","Prediction Market","2025-12","2026","2030","2027","AGI (weak)","Community median","First weakly general AI system; single AI matching human-level reasoning across tasks like SAT math language puzzles and video games","Metaculus (~1700 forecasters)","https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/","https://d3s0w6fek99l5b.cloudfront.net/static/dist/media/metaculus-logo.b6ac828d.svg","1,700 Forecasters on Metaculus: 'Weak AGI' Median Hits October 2027","Metaculus, the prediction platform tracking AI timelines, shows community median for 'weakly general AI'—a single system matching humans across diverse tasks—at October 2027. The platform's forecasters have strong track records on near-term tech predictions. Their aggressive timeline reflects post-GPT-4 recalibration across the forecasting community.",""
"Metaculus Community","Prediction Market","2026-02","2028","2046","2033","AGI (strong)","Community median","Must pass hard Turing test have general robotic capabilities achieve 75%+ on every MMLU task 90% mean and 90% on APPS coding","Metaculus (~1800 forecasters)","https://www.metaculus.com/questions/5121/when-will-the-first-general-ai-system-be-devised-tested-and-publicly-announced/","https://d3s0w6fek99l5b.cloudfront.net/static/dist/media/metaculus-logo.b6ac828d.svg","Metaculus 'Strong AGI' Forecast: June 2033 for Full Human Replacement","Metaculus community puts 'strong AGI'—passing rigorous Turing tests, embodied robotics, 90%+ on all academic benchmarks—at June 2033 median. The 6-year gap between weak and strong AGI captures forecasters' view that crossing human-level is gradual, with major capability tiers separated by years of engineering.",""
"Manifold Markets","Prediction Market","2026-01","2026","2040","2032","AGI","47% before 2028","AGI can theoretically perform any intellectual task that a human being can; adversarial Turing test passed by 2035","Manifold Markets (~1100 contributors)","https://manifold.markets/ManifoldAI/agi-when-resolves-to-the-year-in-wh-d5c5ad8e4708","https://manifold.markets/_next/image?url=%2Flogo.svg&w=32&q=75","Manifold Prediction Market: 47% Odds AGI Arrives Before 2028","Manifold Markets, a play-money prediction market with over 1,100 participants, puts 47% probability on AGI before 2028—just two years out. The platform's median lands at 2032. Prediction markets aggregate diverse opinions and incentivize accuracy, making them potentially more reliable than single-expert forecasts. The near-term odds are shockingly high.",""
"Kalshi","Prediction Market","2026-01","2026","2040","2032","AGI","40% by 2030","OpenAI achieving AGI per their internal definition","Kalshi prediction market","https://kalshi.com/markets/kxoaiagi/openai-achieves-agi/oaiagi","https://kalshi.com/logo.svg","Real-Money Market Kalshi: 40% Odds OpenAI Hits AGI by 2030","Kalshi, a regulated real-money prediction market, shows 40% probability that OpenAI achieves AGI (by their own definition) by 2030. Real money on the line typically produces more calibrated forecasts than surveys or punditry. The market's relatively high near-term odds suggest traders believe OpenAI's internal roadmaps are credible.",""
"Polymarket","Prediction Market","2026-01","2027","2040","2035","AGI","9% by 2027","OpenAI announces it has achieved AGI","Polymarket","https://polymarket.com/event/openai-announces-it-has-achieved-agi-before-2027","https://polymarket.com/_next/image?url=%2Fimages%2Flogo.png&w=64&q=75","Crypto Prediction Market: Just 9% Odds OpenAI Declares AGI This Year","Polymarket, the crypto-based prediction market, gives only 9% odds that OpenAI announces AGI achievement by end of 2027—far lower than CEO rhetoric suggests. The market's skepticism may reflect disbelief in OpenAI's AGI definition (will they just declare victory?) or genuine doubt about capability timelines.",""
"Samotsvety Forecasting","Survey","2026-01","2026","2164","2041","AGI","50% by 2041","AGI broadly defined; 10% in 2026; 50% by 2041; 90% by 2164; 8 elite forecasters","EA Forum - Update to Samotsvety AGI Timelines (January 2026)","https://forum.effectivealtruism.org/posts/ByBBqwRXWqX5m9erL/update-to-samotsvety-agi-timelines","","Elite Forecasting Team: 10% Chance AGI This Year, 50% by 2041","Samotsvety, an elite forecasting collective with strong track records, updated their AGI timeline in January 2026: 10% odds this year, 50% by 2041, 90% by 2164. The massive confidence interval (138 years between 10% and 90%) captures genuine uncertainty. Their 10% for 2026 is notably higher than most experts assign to such near-term AGI.",""
"Goodhart Labs Dashboard","Prediction Market","2026-01","2027","2045","2031","AGI","80% CI: 2027-2045","Combined forecast from Metaculus Samotsvety Kalshi and other sources","AGI Timelines Dashboard (January 5 2026)","https://agi.goodheartlabs.com/","","Aggregated Forecasts: AGI Most Likely 2031, 80% Confidence Between 2027-2045","Goodhart Labs built a meta-dashboard aggregating Metaculus, Samotsvety, Kalshi, and other forecasting sources. The combined estimate: median 2031, with 80% confidence between 2027 and 2045. The 18-year spread reflects real uncertainty, but the central tendency landing in the early 2030s shows remarkable convergence across forecasting methodologies.",""
